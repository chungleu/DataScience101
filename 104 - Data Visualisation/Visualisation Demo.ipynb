{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib basic Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0, 2, 0.01)\n",
    "voltage = 1 + np.sin(2 * np.pi * time)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(time, voltage)\n",
    "ax.set(xlabel='time (s)', ylabel='voltage (mV)', title='OOh nice graph')\n",
    "ax.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('simple wavey.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = 50\n",
    "x = np.random.rand(random_num)\n",
    "y = np.random.rand(random_num)\n",
    "\n",
    "colours = np.random.rand(random_num)\n",
    "area = (30 * np.random.rand(random_num)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y, c=colours, s=area, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot - Polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data\n",
    "N = 150\n",
    "radius = 2 * np.random.rand(N)\n",
    "theta = 2 * np.pi * np.random.rand(N)\n",
    "\n",
    "area = 200 * radius**2\n",
    "colours = theta\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection = 'polar')\n",
    "ax.scatter(theta, radius, c=colours, s=area, cmap='hsv', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('penguins')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Bigger bod = longer bill?')\n",
    "\n",
    "sns.scatterplot(data=df, x='flipper_length_mm', y='bill_depth_mm', hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from branca.element import Figure\n",
    "from folium.plugins import HeatMapWithTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap = folium.Map(location=[51.508446, -0.113687], zoom_start=19)\n",
    "fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap2 = folium.Map(location=[51.508446, -0.113687])\n",
    "\n",
    "folium.TileLayer('Stamen Terrain').add_to(fmap2)\n",
    "folium.TileLayer('Stamen Toner').add_to(fmap2)\n",
    "folium.TileLayer('Stamen Water Color').add_to(fmap2)\n",
    "folium.LayerControl().add_to(fmap2)\n",
    "\n",
    "folium.Marker(location=[51.5, -0.113], popup='Food market', tooltip='Check this out').add_to(fmap2)\n",
    "folium.Marker(location=[51.49, -0.12], popup='Hipster Bar', tooltip='Check this out too').add_to(fmap2)\n",
    "\n",
    "fmap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New York Mass Transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.giphy.com/media/HudvNjWRtXEBi/giphy.webp\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"https://i.giphy.com/media/HudvNjWRtXEBi/giphy.webp\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Options\n",
    "**1** You can start at the beginning with the rawest mta_1706.csv I've been able to find. It is however 1.4GB!\n",
    "This will let you learn and operate the pre-processing steps yourself.\n",
    "It illustrates the data wrangling we need to do to refine data for specific visualisations\n",
    " - Either download directly from Kaggle: https://www.kaggle.com/stoney71/new-york-city-transport-statistics\n",
    " - Or grab from the Cog Tech Community box: https://ibm.ent.box.com/folder/127757715737\n",
    "\n",
    "**2** You can skip the pre-processing and use the much smaller pre-processed file 'pre-processed buses.csv'. If you do, skip to the 'Shortcut without Pre-Processing section'\n",
    " - Grab from the Cog Tech Community box: https://ibm.ent.box.com/folder/127757715737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take some time\n",
    "%%time\n",
    "df = pd.read_csv('mta_1706.csv', error_bad_lines=False, warn_bad_lines=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is from 2017 for the month of June\n",
    "# We want just one day's data and only specific features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['RecordedAtTime'].str.split(' ').apply(lambda x:x[0]=='2017-06-01')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['RecordedAtTime', 'VehicleRef', 'VehicleLocation.Latitude', 'VehicleLocation.Longitude']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to drop duplicates\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for is nulls\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to drop null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like our RecordedAtTime isn't in a datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Recorded Time to DateTime\n",
    "df['RecordedAtTime'] = pd.to_datetime(df['RecordedAtTime'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to track buses every hour, not every minute or second\n",
    "# So our final map will show 24 segments (you can break it down to minutes if you really want)\n",
    "\n",
    "# create Hour Column\n",
    "df['Hour'] = df['RecordedAtTime'].apply(lambda x: x.hour+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want the buses' last positions every hour\n",
    "df2 = pd.DataFrame(df.groupby(['Hour', 'VehicleRef'])['RecordedAtTime'].max())\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-add the index column so we don't use the hour column as the index\n",
    "df2.reset_index(inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df and df2 to get our bus locations at the end of every hour\n",
    "df3 = pd.merge(df2, df,\n",
    "              left_on=['Hour', 'VehicleRef', 'RecordedAtTime'],\n",
    "              right_on=['Hour', 'VehicleRef', 'RecordedAtTime'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as our pre-processed csv\n",
    "df3.to_csv('PreProcessedBuses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortcut without Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('Pre-Processed Buses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HeatMapWithTime takes data in a specific format\n",
    "# Needs lat and long in nested arrays for each hour position\n",
    "\n",
    "[\n",
    "    [[Bus1 LL], [Bus2 LL], [Bus3 LL], ... ], # Hour 1\n",
    "    [[Bus1 LL], [Bus2 LL], [Bus3 LL], ... ], # Hour 2\n",
    "    [[Bus1 LL], [Bus2 LL], [Bus3 LL], ... ], # Hour 3 ...\n",
    "    ....\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to refine our pre-processed data into this format for our HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry if you don't understand this\n",
    "# We're looping through our pre-processed data\n",
    "# For each hour, we're finding each bus' final location, then adding that to a list of Lat/Long for that hour\n",
    "# Then adding each hour's list of Lat/Longs to our nested array\n",
    "\n",
    "lat_long_na = []\n",
    "for i in range(1, 25):\n",
    "    location = []\n",
    "    # iterrates over rows and returns index and instance (contents)\n",
    "    for index, instance, in df3[df3['Hour'] ==i].iterrows():\n",
    "        print(instance) # shows each bus location each hour, from which we're \n",
    "        location.append([instance['VehicleLocation.Latitude'], instance['VehicleLocation.Longitude']])\n",
    "    \n",
    "    lat_long_na.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our our lat long nested array\n",
    "lat_long_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our core map\n",
    "NYfig = Figure(width=700, height=700)\n",
    "NYmap = folium.Map(location=[40.712, -74.005], zoom_start=10)\n",
    "NYfig.add_child(NYmap)\n",
    "\n",
    "# Create our heat map and add it to the core map\n",
    "heatmap = HeatMapWithTime(lat_long_na,\n",
    "               radius=5,\n",
    "               auto_play=True,\n",
    "               position='bottomright')\n",
    "heatmap.add_to(NYmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
